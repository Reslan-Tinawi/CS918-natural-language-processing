{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85f0704-260b-4a76-8e42-8d6800b329ca",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e061602-eb67-4793-a156-afdf96a7da87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:23:30.481545Z",
     "iopub.status.busy": "2024-03-24T00:23:30.481545Z",
     "iopub.status.idle": "2024-03-24T00:23:33.271555Z",
     "shell.execute_reply": "2024-03-24T00:23:33.271555Z",
     "shell.execute_reply.started": "2024-03-24T00:23:30.481545Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from model_training_utils import training_loop, plot_metrics\n",
    "from models import LSTM\n",
    "from text_preprocessing_utils import preprocess_tweet\n",
    "from tweet_data_set import TweetsDataset\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"torchtext version: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "441f7e56185c8b85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8b9e49cc9d0ea52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.environ[\n",
    "    \"WANDB_NOTEBOOK_NAME\"] = r\"C:\\Users\\Reslan Al Tinawi\\Desktop\\CS918-natural-language-processing\\assignment-2\\03-LSTM.ipynb\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb3d155a4f89428",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc67fe50b78ff6e9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99d3fe0d-51ce-41a6-88d7-4825bc119ebd",
   "metadata": {},
   "source": [
    "# Load GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_embedding(embedding_file):\n",
    "    glove_embedding_dict = {}\n",
    "\n",
    "    with open(embedding_file, encoding=\"utf8\") as embedding_file:\n",
    "        for line in embedding_file:\n",
    "            tokens = line.split()\n",
    "            word = tokens[0]\n",
    "            word_embedding_vector = np.array(tokens[1:], dtype=np.float64)\n",
    "            glove_embedding_dict[word] = word_embedding_vector\n",
    "\n",
    "    return glove_embedding_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "191513b4e7b5fd9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a9c2d-de2e-498f-8d27-229fb6171883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:25:45.296636Z",
     "iopub.status.busy": "2024-03-24T00:25:45.296636Z",
     "iopub.status.idle": "2024-03-24T00:25:55.216559Z",
     "shell.execute_reply": "2024-03-24T00:25:55.216559Z",
     "shell.execute_reply.started": "2024-03-24T00:25:45.296636Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding_dict = load_embedding(\"data/glove.6B/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of words in GloVe embedding: {len(glove_embedding_dict)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a47a4f2058eeff25",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57e59ab6-e225-48f3-bd22-2edb3d8cc06a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aca9e2-f752-4316-8d7f-99d67913303c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:27:32.148694Z",
     "iopub.status.busy": "2024-03-24T00:27:32.148694Z",
     "iopub.status.idle": "2024-03-24T00:27:32.165266Z",
     "shell.execute_reply": "2024-03-24T00:27:32.164260Z",
     "shell.execute_reply.started": "2024-03-24T00:27:32.148694Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(file_name: str):\n",
    "    data_list = []\n",
    "\n",
    "    with open(f\"data/semeval-tweets/{file_name}.txt\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            data_list.append(fields)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data=data_list,\n",
    "        columns=[\n",
    "            \"tweet_id\",\n",
    "            \"tweet_sentiment\",\n",
    "            \"tweet_text\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data = read_data(\"twitter-training-data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bf9f7c43bd44c8a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_data = read_data(\"twitter-dev-data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77d2e20b9cd88fdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_1_data = read_data(\"twitter-test1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a1050a777221b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_2_data = read_data(\"twitter-test2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a18e6dc7d079044",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_3_data = read_data(\"twitter-test3\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63cd2bef7fec9a18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06f15948a505f27",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4dddbfe9-13c5-44bf-8cf1-b222e2fcae4e",
   "metadata": {},
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build the vocabulary **only** on the training data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69efa0f54905befb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b918f691316cd4d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_tweets_preprocessed = [preprocess_tweet(tweet, tokenizer) for tweet in training_data[\"tweet_text\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7b26013dd11762b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_tweets_preprocessed = [preprocess_tweet(tweet, tokenizer) for tweet in development_data[\"tweet_text\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b7b1b93eb0a08c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10704b4e5ba8c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "vocab = build_vocab_from_iterator(training_tweets_preprocessed, specials=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:28:05.861768Z",
     "iopub.status.busy": "2024-03-24T00:28:05.861768Z",
     "iopub.status.idle": "2024-03-24T00:28:05.891609Z",
     "shell.execute_reply": "2024-03-24T00:28:05.891609Z",
     "shell.execute_reply.started": "2024-03-24T00:28:05.861768Z"
    }
   },
   "id": "4854271a-c8ae-4cca-940c-7e38926b233a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f267fc539c7c9d88",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "137c6763-a426-4ccd-ac24-1937c5da05f2",
   "metadata": {},
   "source": [
    "# Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de938f04cd7762",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = torch.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a10921ad9b095f00",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unknown_words = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683c817914516d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for word, idx in tqdm(vocab.get_stoi().items()):\n",
    "    if word in glove_embedding_dict:\n",
    "        embedding_matrix[idx] = torch.tensor(glove_embedding_dict[word])\n",
    "    else:\n",
    "        unknown_words.append(word)\n",
    "        embedding_matrix[idx] = torch.randn(embedding_dim)"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:31:33.183130Z",
     "iopub.status.busy": "2024-03-24T00:31:33.183130Z",
     "iopub.status.idle": "2024-03-24T00:31:33.221333Z",
     "shell.execute_reply": "2024-03-24T00:31:33.220829Z",
     "shell.execute_reply.started": "2024-03-24T00:31:33.183130Z"
    }
   },
   "id": "6efd976d-9a3a-4a03-90bd-04db5f41bfed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe6ade-e82c-4b7f-b20a-d4432e664c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(unknown_words)} ({len(unknown_words) / len(vocab):.2f}%) words in the vocabulary that are not in the GloVe embedding.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7bf991d8de7ce62",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(unknown_words[:100])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6132898be4281e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e58e6fed708540"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(training_data['tweet_sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8708b45092bd75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1759eca587f6e230",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(training_data['tweet_id'], training_tweets_preprocessed, training_data[\"tweet_sentiment\"],\n",
    "                              vocab, encoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46dc6e64955ff882",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_dataset = TweetsDataset(development_data['tweet_id'], development_tweets_preprocessed,\n",
    "                                    development_data[\"tweet_sentiment\"], vocab, encoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff55398c569e7d03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Development dataset size: {len(development_dataset)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2988bd076a398dc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    tweet_ids = np.array([item[0] for item in batch])\n",
    "    tweets = [item[1] for item in batch]\n",
    "    labels = np.array([item[2] for item in batch])\n",
    "\n",
    "    padded_tweets = pad_sequence(tweets, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "    return tweet_ids, padded_tweets, torch.from_numpy(labels).to(dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cabb4ca58aa179be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bd40852f451e4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_dataloader = DataLoader(development_dataset, batch_size=256, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198fec9103594fdb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eed4c744d80e55c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 3\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = LSTM(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814311f371ddb400",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93aa7f45cfafb01a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8119713804a58d06",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif \"weight\" in name:\n",
    "                nn.init.orthogonal_(param)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df9f8606281c7e2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.apply(initialize_weights)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2304fafbe90a6c84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.embedding.weight.data = embedding_matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93a6c62af23bcb7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# lr = 5e-4\n",
    "lr = 0.1\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830be628b22c84a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1b8013df1e138a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe7ada9c7442f53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_epochs = 30"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc02ecbbb2340887",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"sentiment-analysis\",\n",
    "    name=\"glove-lstm-5\",\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Bi-LSTM\",\n",
    "        \"features\": \"GloVe embedding\",\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": 10,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"loss_function\": \"CrossEntropyLoss\",\n",
    "        \"seed\": 42,\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb3bdb22effb3d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "metrics = training_loop(\n",
    "    n_epochs,\n",
    "    train_dataloader,\n",
    "    development_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    wandb_run,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5d6d68abd4eb8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_metrics(metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50e4f7933eda7808",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97f2ddfa487a2343"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
