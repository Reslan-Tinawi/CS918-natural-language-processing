{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/semeval-tweets/twitter-training-data.txt\", encoding=\"utf8\") as f:\n",
    "    data = f.readlines()\n",
    "    data = [line.strip().split(\"\\t\") for line in data]\n",
    "    data = pd.DataFrame(data, columns=[\"id\", \"label\", \"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_user_mentions(tweet: str):\n",
    "    user_handle_pattern = re.compile(\"(@[a-zA-Z0-9_]+)\")\n",
    "\n",
    "    return user_handle_pattern.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_tweet_hashtag(tweet: str):\n",
    "    hashtag_pattern = re.compile(\"#(\\w+)\")\n",
    "\n",
    "    return hashtag_pattern.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_url(tweet: str):\n",
    "    url_pattern = re.compile(\n",
    "        \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    )\n",
    "    tweet = url_pattern.sub(\"\", tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(tweet: str):\n",
    "    special_characters_pattern = re.compile(\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "    return special_characters_pattern.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_digits(tweet: str):\n",
    "    digits_pattern = re.compile(r\"\\b\\d+\\b\")\n",
    "    # single character word: \\b\\w{1}\\b\n",
    "\n",
    "    return digits_pattern.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(tokenizer=\"spacy\", language=\"en_core_web_sm\")\n",
    "# tokenizer = get_tokenizer(tokenizer='basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet: str, nlp) -> list[str]:\n",
    "    tweet = remove_url(tweet)  # what about emails?\n",
    "    tweet = remove_user_mentions(tweet)\n",
    "    tweet = remove_tweet_hashtag(tweet)\n",
    "    # tweet = remove_special_characters(tweet)\n",
    "    tweet = remove_digits(tweet)\n",
    "    # remove multiple spaces\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet)\n",
    "    # remove leading and trailing spaces\n",
    "    tweet = tweet.strip()\n",
    "    # lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # tokenize\n",
    "    doc = nlp(tweet)\n",
    "    tweet_tokens = [\n",
    "        token.text\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get 10 random tweets and apply the preprocessing\n",
    "for tweet in data[\"tweet\"].sample(10):\n",
    "    print(tweet)\n",
    "    print(preprocess_tweet(tweet, nlp))\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed_tweets = [preprocess_tweet(tweet, nlp) for tweet in data[\"tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "vocab = build_vocab_from_iterator(preprocessed_tweets, specials=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab.lookup_indices([\"hello\", \"world\", \"trump\", \"this\", \"is\", \"good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tweet_to_ids(tweet: str):\n",
    "    tweet_ids = vocab.lookup_indices(tweet)\n",
    "    return tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = list(map(convert_tweet_to_ids, preprocessed_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.lookup_tokens(tweet_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataSet(Dataset):\n",
    "    def __init__(self, tweet_ids_list, labels_list):\n",
    "        self.tweet_ids_list = tweet_ids_list\n",
    "        self.labels_list = labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweet_ids_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tweet_ids_list[idx], self.labels_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TweetDataSet(tweet_ids, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
