{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d1883c4e2a8ac2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Install needed packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa60358af38006",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "! pip install ekphrasis wordcloud wordsnake nltk contractions transformers tqdm emoji umap-learn pillow wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f3440-d7f3-43db-bebe-9ad2a6463292",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c351f-e3d2-46d3-90f4-20f4cf70ca37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import transformers\n",
    "import umap\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from scripts.data_loading_utils import load_embedding, read_tweet_data\n",
    "from scripts.model_training_utils import plot_classification_results\n",
    "from scripts.model_training_utils import plot_metrics, training_loop\n",
    "from scripts.models import BERTClassifier, LSTM, count_parameters\n",
    "from scripts.models import LSTMWithAttention\n",
    "from scripts.plotting_utilities import generate_ngram_frequencies, generate_wordcloud_with_ngrams, \\\n",
    "    plot_top_common_ngrams\n",
    "from scripts.text_preprocessing_utils import advanced_preprocessing\n",
    "from scripts.tweet_data_set import BERTTweetsDataset\n",
    "from scripts.tweet_data_set import TweetsDataset\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"torchtext version: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76b4f9baca109d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d5318-8dff-42c0-8ab7-7275b70e5bb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef52516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7984269-de76-4bad-a4b1-9c33a4b9b039",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup Data Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4479d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = Path(os.path.join(os.getcwd(), \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "models_weights_dir_path = Path(os.path.join(os.getcwd(), \"models_weights\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb8db62b44340e8"
  },
  {
   "cell_type": "markdown",
   "id": "fc35c19a-c43c-4d06-8e9b-19131a35ea5d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d3c96-ced7-4d3b-b7ac-9a6d91d8ffd9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = read_tweet_data(\"twitter-training-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bc140-a6f1-4dad-883f-793901ff4409",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "development_data = read_tweet_data(\"twitter-dev-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_data = read_tweet_data(\"twitter-test1-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079efbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data = read_tweet_data(\"twitter-test2-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_data = read_tweet_data(\"twitter-test3-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c45cf-7b95-4dd9-b8fc-7edc25d97987",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fe9dc-4b08-4597-8fa8-3f90c47c7f50",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training data: {training_data['tweet_sentiment'].value_counts().to_dict()}\")\n",
    "print(\n",
    "    f\"Development data: {development_data['tweet_sentiment'].value_counts().to_dict()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cef78-e2df-4e77-987a-06450e6da4ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Training data: {training_data['tweet_sentiment'].value_counts(normalize=True).to_dict()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Development data: {development_data['tweet_sentiment'].value_counts(normalize=True).to_dict()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89864e94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Cleaning & Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a5179d157f817",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9d12cf8bd627a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data[\"tweet_text_cleaned\"] = training_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: advanced_preprocessing(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d1ca489005560",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_tweets = training_data[training_data[\"tweet_sentiment\"] == \"positive\"]\n",
    "negative_tweets = training_data[training_data[\"tweet_sentiment\"] == \"negative\"]\n",
    "neutral_tweets = training_data[training_data[\"tweet_sentiment\"] == \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d550032439dc5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7320a7d23062011",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96187af3d7b33c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933210a86f051dd4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9956e983db954269",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate n-grams frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239ad522820dabb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "positive_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "positive_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e0296289211ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "negative_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "negative_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220d6a1a3f24e30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neutral_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "neutral_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "neutral_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf29ab1f9bbc174",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [positive_unigram_freq, positive_bigram_freq, positive_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28292c54e83e76",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [negative_unigram_freq, negative_bigram_freq, negative_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2e5082289fb89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [neutral_unigram_freq, neutral_bigram_freq, neutral_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1352d642c99f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate wordclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f097a3267e73ab5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "        [positive_unigram_freq, positive_bigram_freq, positive_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Positive tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b1a1a9b2bb9d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "        [negative_unigram_freq, negative_bigram_freq, negative_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Negative tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dcd64d484b17eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "        [neutral_unigram_freq, neutral_bigram_freq, neutral_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Neutral tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f52fc6c00c2d6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Traditional classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45162877121e8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b032eec7d5bef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd946bae2896c2e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_data[\"tweet_text_cleaned\"],\n",
    "    training_data[\"tweet_sentiment\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=training_data[\"tweet_sentiment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940961240c2196",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training data: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Test data: {y_test.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d94a150f1d9626",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a Naive Bayes classifier\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),  # Placeholder, will be tuned by GridSearchCV\n",
    "        (\"clf\", MultinomialNB()),  # Naive Bayes classifier\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e9881f216f408",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect\": [TfidfVectorizer(), CountVectorizer()],\n",
    "    \"vect__stop_words\": [\"english\"],\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    \"vect__min_df\": [5, 10, 15],\n",
    "    \"vect__max_features\": (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],  # Unigrams or bigrams\n",
    "    \"clf__alpha\": (0.01, 0.1, 1),  # Additive (Laplace/Lidstone) smoothing parameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be833cc5dc1333f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215526263d92824",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1efe95614c2088",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94565f2817b4c26e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the best grid search pipeline on the test dataset\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da699885cb335d2b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create confusion matrix display\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"negative\", \"neutral\", \"positive\"],\n",
    "    yticklabels=[\"negative\", \"neutral\", \"positive\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cea77a7f22b0e1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_vectorizer = grid_search.best_estimator_.named_steps[\"vect\"]\n",
    "best_classifier = grid_search.best_estimator_.named_steps[\"clf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a1e4f430f232a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_vectorizer.get_feature_names_out().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e5c339830b292",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_classifier.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179adf95ee82848c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45728d44615f4f47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the most important features (words) for each class\n",
    "def get_most_important_features(vectorizer, classifier, n=10):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topn_class1 = sorted(\n",
    "        zip(classifier.feature_log_prob_[0], feature_names), reverse=True\n",
    "    )[:n]\n",
    "    topn_class2 = sorted(\n",
    "        zip(classifier.feature_log_prob_[1], feature_names), reverse=True\n",
    "    )[:n]\n",
    "    topn_class3 = sorted(\n",
    "        zip(classifier.feature_log_prob_[2], feature_names), reverse=True\n",
    "    )[:n]\n",
    "\n",
    "    print(f\"Top {n} most important features for each class:\")\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        print(f\"\\n{class_label}:\")\n",
    "        for coef, feat in (\n",
    "                topn_class1 if i == 0 else topn_class2 if i == 1 else topn_class3\n",
    "        ):\n",
    "            print(f\"{feat} ({coef:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1fea9d28bc9609",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_most_important_features(best_vectorizer, best_classifier, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeefe35611fa28",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6f769bb231c0e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),  # Placeholder, will be tuned by GridSearchCV\n",
    "        (\"clf\", LogisticRegression(max_iter=500)),  # Logistic Regression classifier\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5ed6eefdd1a93",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect\": [TfidfVectorizer(), CountVectorizer()],\n",
    "    \"vect__stop_words\": [\"english\"],\n",
    "    \"vect__min_df\": [10, 15, 25],\n",
    "    \"vect__max_features\": (500, 1000),\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],  # Unigrams or bigrams\n",
    "    \"clf__C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0e31f8784ecb3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5f800efdf5c69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72862ff86bc6af62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a613752f7e4e55",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the best grid search pipeline on the test dataset\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f31bc9415fc03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create confusion matrix display\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"negative\", \"neutral\", \"positive\"],\n",
    "    yticklabels=[\"negative\", \"neutral\", \"positive\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c1c1d53383500",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e373ec7ebcbdc38",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=5, stop_words=\"english\", ngram_range=(1, 3), max_features=5000\n",
    ")\n",
    "tfidf_word_doc_matrix = tfidf_vectorizer.fit_transform(\n",
    "    training_data[\"tweet_text_cleaned\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c71b802208187",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_embedding = umap.UMAP(metric=\"hellinger\").fit(tfidf_word_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cb61c930af0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=tfidf_embedding.embedding_[:, 0],\n",
    "    y=tfidf_embedding.embedding_[:, 1],\n",
    "    hue=training_data[\"tweet_sentiment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e9f9a3fb213a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c342e",
   "metadata": {},
   "source": [
    "## Load GloVe embedding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64951242",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file_name = \"glove.6B.100d.txt\"\n",
    "glove_embedding_dict = load_embedding(data_dir_path / embedding_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of words in GloVe embedding: {len(glove_embedding_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5892d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max tokens to 5000\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "min_freq = 5\n",
    "max_tokens = 5000\n",
    "vocab = build_vocab_from_iterator(\n",
    "    iterator=training_data[\"tweet_text_cleaned\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    "    max_tokens=max_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ab39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c7a1e",
   "metadata": {},
   "source": [
    "## Build embedding matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = torch.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282279f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tqdm(vocab.get_stoi().items()):\n",
    "    if word in glove_embedding_dict:\n",
    "        embedding_matrix[idx] = torch.tensor(glove_embedding_dict[word])\n",
    "    else:\n",
    "        unknown_words.append(word)\n",
    "        embedding_matrix[idx] = torch.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c09798",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(unknown_words)} ({len(unknown_words) / len(vocab):.2f}%) words in the vocabulary that are not in the GloVe embedding.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833deab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595badb",
   "metadata": {},
   "source": [
    "## Define Datasets and Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60561eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(training_data[\"tweet_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150792cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_dataset = TweetsDataset(\n",
    "    tweet_ids=training_data['tweet_id'], tweets=training_data['tweet_text_cleaned'],\n",
    "    labels=training_data['tweet_sentiment'], vocab=vocab, label_encoder=encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "development_dataset = TweetsDataset(\n",
    "    tweet_ids=development_data['tweet_id'], tweets=development_data['tweet_text_cleaned'],\n",
    "    labels=development_data['tweet_sentiment'], vocab=vocab, label_encoder=encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_dataset = TweetsDataset(\n",
    "    tweet_ids=test1_data['tweet_id'], tweets=test1_data['tweet_text_cleaned'],\n",
    "    labels=test1_data['tweet_sentiment'], vocab=vocab, label_encoder=encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a072b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_dataset = TweetsDataset(\n",
    "    tweet_ids=test2_data['tweet_id'], tweets=test2_data['tweet_text_cleaned'],\n",
    "    labels=test2_data['tweet_sentiment'], vocab=vocab, label_encoder=encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_dataset = TweetsDataset(\n",
    "    tweet_ids=test3_data['tweet_id'], tweets=test3_data['tweet_text_cleaned'],\n",
    "    labels=test3_data['tweet_sentiment'], vocab=vocab, label_encoder=encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea70e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    tweet_ids = np.array([item[0] for item in batch])\n",
    "    tweets = [item[1] for item in batch]\n",
    "    labels = np.array([item[2] for item in batch])\n",
    "\n",
    "    padded_tweets = pad_sequence(tweets, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "    return tweet_ids, padded_tweets, torch.from_numpy(labels).to(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd76b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    bert_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "development_dataloader = DataLoader(\n",
    "    development_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test1_dataloader = DataLoader(\n",
    "    test1_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test2_dataloader = DataLoader(\n",
    "    test2_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test3_dataloader = DataLoader(\n",
    "    test3_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dd64e",
   "metadata": {},
   "source": [
    "## LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23588aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 3\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd76a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The LSTM model has {count_parameters(lstm_model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.embedding.weight.data = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 5e-4\n",
    "\n",
    "# TODO:\n",
    "# add class weights to the loss function: https://stackoverflow.com/questions/61414065/pytorch-weight-in-cross-entropy-loss\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50671e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"sentiment-analysis\",\n",
    "    name=\"lstm-with-attention\",\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Bi-LSTM with attention\",\n",
    "        \"features\": \"GloVe embedding\",\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"loss_function\": \"CrossEntropyLoss\",\n",
    "        \"seed\": 42,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lstm_model_path = models_weights_dir_path / \"lstm_model.pt\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f54598c29f00171b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5937507",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = training_loop(\n",
    "    n_epochs,\n",
    "    train_dataloader,\n",
    "    development_dataloader,\n",
    "    lstm_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    False,\n",
    "    wandb_run,\n",
    "    lstm_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f32ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e58b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_results(lstm_model, development_dataloader, encoder, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d82eb",
   "metadata": {},
   "source": [
    "## LSTM with Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 3\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model = LSTMWithAttention(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce720f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The LSTM with attention model has {count_parameters(lstm_with_attention_model):,} trainable parameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a154c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model.embedding.weight.data = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 5e-4\n",
    "\n",
    "# TODO:\n",
    "# add class weights to the loss function: https://stackoverflow.com/questions/61414065/pytorch-weight-in-cross-entropy-loss\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_with_attention_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9320606",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model = lstm_with_attention_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"sentiment-analysis\",\n",
    "    name=\"lstm-with-attention\",\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"Bi-LSTM with attention\",\n",
    "        \"features\": \"GloVe embedding\",\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"loss_function\": \"CrossEntropyLoss\",\n",
    "        \"seed\": 42,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lstm_with_attention_model_path = models_weights_dir_path / \"lstm_with_attention_model.pt\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68e7eac2310abd2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b83cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = training_loop(\n",
    "    n_epochs,\n",
    "    train_dataloader,\n",
    "    development_dataloader,\n",
    "    lstm_with_attention_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    False,\n",
    "    wandb_run,\n",
    "    lstm_with_attention_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd19d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_results(lstm_with_attention_model, development_dataloader, encoder, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2aa26c",
   "metadata": {},
   "source": [
    "## BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = \"bert-base-uncased\"\n",
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(transformer_name)\n",
    "bert_transformer = transformers.AutoModel.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_transformer.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca10271",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_dataset = BERTTweetsDataset(\n",
    "    tweet_ids=training_data[\"tweet_id\"],\n",
    "    tweets=training_data[\"tweet_text\"],\n",
    "    labels=training_data[\"tweet_sentiment\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_development_dataset = BERTTweetsDataset(\n",
    "    tweet_ids=development_data[\"tweet_id\"],\n",
    "    tweets=development_data[\"tweet_text\"],\n",
    "    labels=development_data[\"tweet_sentiment\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test1_dataset = BERTTweetsDataset(\n",
    "    tweet_ids=test1_data[\"tweet_id\"],\n",
    "    tweets=test1_data[\"tweet_text\"],\n",
    "    labels=test1_data[\"tweet_sentiment\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test2_dataset = BERTTweetsDataset(\n",
    "    tweet_ids=test2_data[\"tweet_id\"],\n",
    "    tweets=test2_data[\"tweet_text\"],\n",
    "    labels=test2_data[\"tweet_sentiment\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f091cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test3_dataset = BERTTweetsDataset(\n",
    "    tweet_ids=test3_data[\"tweet_id\"],\n",
    "    tweets=test3_data[\"tweet_text\"],\n",
    "    labels=test3_data[\"tweet_sentiment\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = bert_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a64970",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f81c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_dataloader = DataLoader(\n",
    "    bert_train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "bert_development_dataloader = DataLoader(\n",
    "    bert_development_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "bert_test1_dataloader = DataLoader(\n",
    "    bert_test1_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "bert_test2_dataloader = DataLoader(\n",
    "    bert_test2_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "bert_test3_dataloader = DataLoader(\n",
    "    bert_test3_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sentiment_model = BERTClassifier(\n",
    "    transformer=bert_transformer, output_dim=len(encoder.classes_), freeze=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The BERT sentiment model has {count_parameters(bert_sentiment_model):,} trainable parameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d61a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(bert_sentiment_model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sentiment_model = bert_sentiment_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"sentiment-analysis\",\n",
    "    name=\"bert\",\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"BERT\",\n",
    "        \"features\": \"BERT\",\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": 5,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"loss_function\": \"CrossEntropyLoss\",\n",
    "        \"seed\": 42,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_sentiment_model_path = models_weights_dir_path / \"bert_sentiment_model.pt\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6db7609451314f79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b07b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    5,\n",
    "    bert_train_dataloader,\n",
    "    bert_development_dataloader,\n",
    "    bert_sentiment_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    True,\n",
    "    wandb_run,\n",
    "    bert_sentiment_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b031ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e3094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f058c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9b642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f381b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eb8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39024583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c53e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4086f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6a2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b942b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bf708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f648a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c4313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
