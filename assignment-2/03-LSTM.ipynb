{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85f0704-260b-4a76-8e42-8d6800b329ca",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e061602-eb67-4793-a156-afdf96a7da87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:23:30.481545Z",
     "iopub.status.busy": "2024-03-24T00:23:30.481545Z",
     "iopub.status.idle": "2024-03-24T00:23:33.271555Z",
     "shell.execute_reply": "2024-03-24T00:23:33.271555Z",
     "shell.execute_reply.started": "2024-03-24T00:23:30.481545Z"
    },
    "ExecuteTime": {
     "end_time": "2024-03-24T16:43:36.246605Z",
     "start_time": "2024-03-24T16:43:31.605297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu118\n",
      "torchtext version: 0.17.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"torchtext version: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:44:31.495196Z",
     "start_time": "2024-03-24T16:44:31.482542Z"
    }
   },
   "id": "81da49e4c9e0ee5f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "441f7e56185c8b85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8b9e49cc9d0ea52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb3d155a4f89428"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dc67fe50b78ff6e9"
  },
  {
   "cell_type": "markdown",
   "id": "99d3fe0d-51ce-41a6-88d7-4825bc119ebd",
   "metadata": {},
   "source": [
    "# Load GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_embedding(embedding_file):\n",
    "    glove_embedding_dict = {}\n",
    "\n",
    "    with open(embedding_file, encoding=\"utf8\") as embedding_file:\n",
    "        for line in embedding_file:\n",
    "            tokens = line.split()\n",
    "            word = tokens[0]\n",
    "            word_embedding_vector = np.array(tokens[1:], dtype=np.float64)\n",
    "            glove_embedding_dict[word] = word_embedding_vector\n",
    "\n",
    "    return glove_embedding_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "191513b4e7b5fd9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a9c2d-de2e-498f-8d27-229fb6171883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:25:45.296636Z",
     "iopub.status.busy": "2024-03-24T00:25:45.296636Z",
     "iopub.status.idle": "2024-03-24T00:25:55.216559Z",
     "shell.execute_reply": "2024-03-24T00:25:55.216559Z",
     "shell.execute_reply.started": "2024-03-24T00:25:45.296636Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding_dict = load_embedding(\"data/glove.6B/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e59ab6-e225-48f3-bd22-2edb3d8cc06a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aca9e2-f752-4316-8d7f-99d67913303c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:27:32.148694Z",
     "iopub.status.busy": "2024-03-24T00:27:32.148694Z",
     "iopub.status.idle": "2024-03-24T00:27:32.165266Z",
     "shell.execute_reply": "2024-03-24T00:27:32.164260Z",
     "shell.execute_reply.started": "2024-03-24T00:27:32.148694Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(file_name: str):\n",
    "    data_list = []\n",
    "\n",
    "    with open(f\"data/semeval-tweets/{file_name}.txt\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            data_list.append(fields)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data=data_list,\n",
    "        columns=[\n",
    "            \"tweet_id\",\n",
    "            \"tweet_sentiment\",\n",
    "            \"tweet_text\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data = read_data(\"twitter-training-data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bf9f7c43bd44c8a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_data = read_data(\"twitter-dev-data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77d2e20b9cd88fdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_1_data = read_data(\"twitter-test1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a1050a777221b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_2_data = read_data(\"twitter-test2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a18e6dc7d079044",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testing_3_data = read_data(\"twitter-test3\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63cd2bef7fec9a18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06f15948a505f27",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4dddbfe9-13c5-44bf-8cf1-b222e2fcae4e",
   "metadata": {},
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build the vocabulary only on the training data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69efa0f54905befb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_user_mentions(tweet: str):\n",
    "    user_handle_pattern = re.compile(\"(@[a-zA-Z0-9_]+)\")\n",
    "\n",
    "    return user_handle_pattern.sub(\"\", tweet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b918f691316cd4d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_tweet_hashtag(tweet: str):\n",
    "    hashtag_pattern = re.compile(\"#(\\w+)\")\n",
    "\n",
    "    return hashtag_pattern.sub(\"\", tweet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2be2e055bcf673e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_url(tweet: str):\n",
    "    url_pattern = re.compile(\n",
    "        \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    )\n",
    "    tweet = url_pattern.sub(\"\", tweet)\n",
    "    return tweet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf07a9bb6fd5af5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_special_characters(tweet: str):\n",
    "    special_characters_pattern = re.compile(\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "    return special_characters_pattern.sub(\"\", tweet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2cb5ca77f5b23d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_digits(tweet: str):\n",
    "    digits_pattern = re.compile(r\"\\b\\d+\\b\")\n",
    "    # single character word: \\b\\w{1}\\b\n",
    "\n",
    "    return digits_pattern.sub(\"\", tweet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64b87cbcfd00bb57",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bfda70d5539bab2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet: str, nlp) -> list[str]:\n",
    "    tweet = remove_url(tweet)  # what about emails?\n",
    "    tweet = remove_user_mentions(tweet)\n",
    "    tweet = remove_tweet_hashtag(tweet)\n",
    "    # tweet = remove_special_characters(tweet)\n",
    "    tweet = remove_digits(tweet)\n",
    "    # remove multiple spaces\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet)\n",
    "    # remove leading and trailing spaces\n",
    "    tweet = tweet.strip()\n",
    "    # lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # tokenize\n",
    "    doc = nlp(tweet)\n",
    "    tweet_tokens = [\n",
    "        token.text\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "\n",
    "    return tweet_tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddbac1083ffc7ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_tweets_preprocessed = [preprocess_tweet(tweet, nlp) for tweet in training_data[\"tweet_text\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7b26013dd11762b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_tweets_preprocessed = [preprocess_tweet(tweet, nlp) for tweet in development_data[\"tweet_text\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b7b1b93eb0a08c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854271a-c8ae-4cca-940c-7e38926b233a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:28:05.861768Z",
     "iopub.status.busy": "2024-03-24T00:28:05.861768Z",
     "iopub.status.idle": "2024-03-24T00:28:05.891609Z",
     "shell.execute_reply": "2024-03-24T00:28:05.891609Z",
     "shell.execute_reply.started": "2024-03-24T00:28:05.861768Z"
    }
   },
   "outputs": [],
   "source": [
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "vocab = build_vocab_from_iterator(training_tweets_preprocessed, specials=special_tokens)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d538d2c-a2f4-4d33-88f9-5444d9487968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:28:06.497190Z",
     "iopub.status.busy": "2024-03-24T00:28:06.497190Z",
     "iopub.status.idle": "2024-03-24T00:28:06.504773Z",
     "shell.execute_reply": "2024-03-24T00:28:06.504773Z",
     "shell.execute_reply.started": "2024-03-24T00:28:06.497190Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c6763-a426-4ccd-ac24-1937c5da05f2",
   "metadata": {},
   "source": [
    "# Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de938f04cd7762",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the embedding matrix\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = torch.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a10921ad9b095f00",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for word, idx in tqdm(vocab.get_stoi().items()):\n",
    "    if word in glove_embedding_dict:\n",
    "        embedding_matrix[idx] = torch.tensor(glove_embedding_dict[word])\n",
    "    else:\n",
    "        embedding_matrix[idx] = torch.randn(embedding_dim)"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T00:31:33.183130Z",
     "iopub.status.busy": "2024-03-24T00:31:33.183130Z",
     "iopub.status.idle": "2024-03-24T00:31:33.221333Z",
     "shell.execute_reply": "2024-03-24T00:31:33.220829Z",
     "shell.execute_reply.started": "2024-03-24T00:31:33.183130Z"
    }
   },
   "id": "6efd976d-9a3a-4a03-90bd-04db5f41bfed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe6ade-e82c-4b7f-b20a-d4432e664c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e58e6fed708540"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, tweet_ids, tweets, labels, vocab, label_encoder):\n",
    "        self.tweet_ids = tweet_ids\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet_id = self.tweet_ids[idx]\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        tweet_tensor = torch.tensor(self.vocab.lookup_indices(tweet))\n",
    "        tweet_label = self.label_encoder.transform([label])\n",
    "\n",
    "        return tweet_id, tweet_tensor, tweet_label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "122e281d5659642d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(training_data['tweet_sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8708b45092bd75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1759eca587f6e230",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(training_data['tweet_id'], training_tweets_preprocessed, training_data[\"tweet_sentiment\"],\n",
    "                              vocab, encoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46dc6e64955ff882",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_dataset = TweetsDataset(development_data['tweet_id'], development_tweets_preprocessed,\n",
    "                                    development_data[\"tweet_sentiment\"], vocab, encoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff55398c569e7d03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Development dataset size: {len(development_dataset)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2988bd076a398dc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    tweet_ids = np.array([item[0] for item in batch])\n",
    "    tweets = [item[1] for item in batch]\n",
    "    labels = np.array([item[2] for item in batch])\n",
    "\n",
    "    padded_tweets = pad_sequence(tweets, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "    return tweet_ids, padded_tweets, torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cabb4ca58aa179be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bd40852f451e4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "development_dataloader = DataLoader(development_dataset, batch_size=256, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198fec9103594fdb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eed4c744d80e55c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, output_dim, num_layers, bidirectional, dropout):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embedding_matrix, padding_idx=vocab[\"<pad>\"])\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            embedding_matrix.size(1),\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        return self.fc(hidden)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a21f1126c7e09714",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = LSTMClassifier(embedding_matrix, hidden_dim=256, output_dim=3, num_layers=2, bidirectional=True,\n",
    "                       dropout=0.2).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814311f371ddb400",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830be628b22c84a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "n_epochs = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc02ecbbb2340887",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, epoch):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "        tweet_ids, tweets, labels = batch\n",
    "\n",
    "        tweets = tweets.to(device)\n",
    "        labels = labels.squeeze().to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(tweets)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "\n",
    "        train_accuracy += torch.sum(predictions == labels).item()\n",
    "\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), train_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b24022acfc95fa0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    evaluation_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
    "            tweet_ids, tweets, labels = batch\n",
    "\n",
    "            tweets = tweets.to(device)\n",
    "            labels = labels.squeeze().to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(tweets)\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "\n",
    "            evaluation_accuracy += torch.sum(predictions == labels).item()\n",
    "\n",
    "            loss = loss_fn(output, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), evaluation_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a792b90d28b2b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "development_loss_list = []\n",
    "\n",
    "train_accuracy_list = []\n",
    "development_accuracy_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_accuracy = train(train_dataloader, model, criterion, epoch)\n",
    "    development_loss, development_accuracy = evaluate(development_dataloader, model, criterion, epoch)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    development_loss_list.append(development_loss)\n",
    "\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    development_accuracy_list.append(development_accuracy)\n",
    "\n",
    "    print(f\"[{epoch + 1}/{n_epochs}], Train Loss: {train_loss:.4f}, Development Loss: {development_loss:.4f}\")\n",
    "    print(f\"[{epoch + 1}/{n_epochs}], Train Accuracy: {train_accuracy / len(training_data):.4f}, \"\n",
    "          f\"Development Accuracy: {development_accuracy / len(development_data):.4f}\")\n",
    "\n",
    "    print(\"=\" * 80)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814349dd4d00569a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "plt.plot(development_loss_list, label=\"Development Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db6a6f9c39ccb48b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy_list, label=\"Train Accuracy\")\n",
    "plt.plot(development_accuracy_list, label=\"Development Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bfbc59704a45f34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c719ed54d202c13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bcd62ae86f9fc836"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "721de01ce8a529d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "499b7f7fdbca5527"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "952e450ec0840d85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d493c5be48eb0027"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c75a1929ee5747a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "471d6fbbfe93dab0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12a103795ef21a28"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9a5df599c8e0598"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "52be1213e857bcda"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da7bc58ea86799a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e61cc107b3345983"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8fc559efc7d00929"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a87f73a3e23f02a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d33916e6347b30e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d687f6a82dd4dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "25de3f5407aba61b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "526e177a2e9544a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1fb78b8a5ecda49f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ceb5d3ac2d9ad3c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7134daec863726"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b7ba2ab878cf987e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d25c614e9bf2527e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet = \"I love this movie\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b61919d9fbbe77eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet_tokens = preprocess_tweet(sample_tweet, nlp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c16093c1f487f6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet_tensor = torch.tensor(vocab.lookup_indices(sample_tweet_tokens)).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96b1a893a9445f04",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    sample_tweet_tensor = sample_tweet_tensor.cuda()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bbb94707b44e7cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model(sample_tweet_tensor)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecdfc38ec7d08b7c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.argmax(model(sample_tweet_tensor))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac46a837f74b029a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet = \"I hate this movie\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136d6d5bb03e066e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet_tokens = preprocess_tweet(sample_tweet, nlp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "716b55b556457358",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tweet_tensor = torch.tensor(vocab.lookup_indices(sample_tweet_tokens)).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba0484031e08b7e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    sample_tweet_tensor = sample_tweet_tensor.cuda()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21804e299953641e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model(sample_tweet_tensor)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a6f3f9e7d205cfe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.argmax(model(sample_tweet_tensor))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154fb33a88706d64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9666c75fa1f093e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
