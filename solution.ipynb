{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6f3440-d7f3-43db-bebe-9ad2a6463292",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c351f-e3d2-46d3-90f4-20f4cf70ca37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import transformers\n",
    "import umap\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.data_loading_utils import load_embedding, read_tweet_data\n",
    "from scripts.model_training_utils import (\n",
    "    get_labels_and_predictions,\n",
    "    plot_confusion_matrix,\n",
    "    plot_metrics,\n",
    "    training_loop,\n",
    ")\n",
    "from scripts.models import LSTM, BERTClassifier, LSTMWithAttention, count_parameters\n",
    "from scripts.plotting_utilities import (\n",
    "    generate_ngram_frequencies,\n",
    "    generate_wordcloud_with_ngrams,\n",
    "    plot_top_common_ngrams,\n",
    ")\n",
    "from scripts.text_preprocessing_utils import preprocess_tweet\n",
    "from scripts.tweet_data_set import BERTTweetsDataset, TweetsDataset\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"torchtext version: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76b4f9baca109d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d5318-8dff-42c0-8ab7-7275b70e5bb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef52516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536eceec",
   "metadata": {},
   "source": [
    "# Setup seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cc77c",
   "metadata": {},
   "source": [
    "Seed random generator to guarantee reproducibility:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7984269-de76-4bad-a4b1-9c33a4b9b039",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup Data Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4479d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = Path(os.path.join(os.getcwd(), \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8db62b44340e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_weights_dir_path = Path(os.path.join(os.getcwd(), \"models_weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba666ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data directory: {data_dir_path}\")\n",
    "print(f\"Models weights directory: {models_weights_dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35c19a-c43c-4d06-8e9b-19131a35ea5d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d3c96-ced7-4d3b-b7ac-9a6d91d8ffd9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = read_tweet_data(data_dir_path / \"twitter-training-data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bc140-a6f1-4dad-883f-793901ff4409",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "development_data = read_tweet_data(data_dir_path / \"twitter-dev-data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_data = read_tweet_data(data_dir_path / \"twitter-test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079efbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data = read_tweet_data(data_dir_path / \"twitter-test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_data = read_tweet_data(data_dir_path / \"twitter-test3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c45cf-7b95-4dd9-b8fc-7edc25d97987",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fe9dc-4b08-4597-8fa8-3f90c47c7f50",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training data: {training_data['tweet_sentiment'].value_counts().to_dict()}\")\n",
    "print(\n",
    "    f\"Development data: {development_data['tweet_sentiment'].value_counts().to_dict()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cef78-e2df-4e77-987a-06450e6da4ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Training data: {training_data['tweet_sentiment'].value_counts(normalize=True).to_dict()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Development data: {development_data['tweet_sentiment'].value_counts(normalize=True).to_dict()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89864e94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Cleaning & Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a5179d157f817",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9d12cf8bd627a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code takes 20 seconds\n",
    "training_data[\"tweet_text_cleaned\"] = training_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: preprocess_tweet(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "development_data[\"tweet_text_cleaned\"] = development_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: preprocess_tweet(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_data[\"tweet_text_cleaned\"] = test1_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: preprocess_tweet(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data[\"tweet_text_cleaned\"] = test2_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: preprocess_tweet(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_data[\"tweet_text_cleaned\"] = test3_data[\"tweet_text\"].apply(\n",
    "    lambda tweet: preprocess_tweet(tweet, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d1ca489005560",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_tweets = training_data[training_data[\"tweet_sentiment\"] == \"positive\"]\n",
    "negative_tweets = training_data[training_data[\"tweet_sentiment\"] == \"negative\"]\n",
    "neutral_tweets = training_data[training_data[\"tweet_sentiment\"] == \"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ef5aa",
   "metadata": {},
   "source": [
    "## Tweet length:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc357965",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"tweet_length\"] = training_data[\"tweet_text\"].str.len()\n",
    "training_data[\"tweet_cleaned_length\"] = training_data[\"tweet_text_cleaned\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=training_data,\n",
    "    x=\"tweet_length\",\n",
    "    hue=\"tweet_sentiment\",\n",
    "    col=\"tweet_sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=training_data,\n",
    "    x=\"tweet_cleaned_length\",\n",
    "    hue=\"tweet_sentiment\",\n",
    "    col=\"tweet_sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956e983db954269",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate n-grams frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239ad522820dabb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "\n",
    "positive_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "\n",
    "positive_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=positive_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e0296289211ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "\n",
    "negative_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "\n",
    "negative_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=negative_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220d6a1a3f24e30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neutral_unigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=1, max_features=1000\n",
    ")\n",
    "\n",
    "neutral_bigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=2, max_features=1000\n",
    ")\n",
    "\n",
    "neutral_trigram_freq = generate_ngram_frequencies(\n",
    "    corpus=neutral_tweets[\"tweet_text_cleaned\"], n_grams=3, max_features=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf29ab1f9bbc174",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [positive_unigram_freq, positive_bigram_freq, positive_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28292c54e83e76",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [negative_unigram_freq, negative_bigram_freq, negative_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2e5082289fb89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_common_ngrams(\n",
    "    [neutral_unigram_freq, neutral_bigram_freq, neutral_trigram_freq]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1352d642c99f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate wordclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f097a3267e73ab5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "    [positive_unigram_freq, positive_bigram_freq, positive_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Positive tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b1a1a9b2bb9d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "    [negative_unigram_freq, negative_bigram_freq, negative_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Negative tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dcd64d484b17eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, n_gram_freq_dict in enumerate(\n",
    "    [neutral_unigram_freq, neutral_bigram_freq, neutral_trigram_freq]\n",
    "):\n",
    "    generate_wordcloud_with_ngrams(n_gram_freq_dict, idx + 1, \"Neutral tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916db01",
   "metadata": {},
   "source": [
    "## UMAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61960f86",
   "metadata": {},
   "source": [
    "Generate a scatter plot of the data by reducing its dimensionality using TF-IDF features and UMAP algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bbdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=5, stop_words=\"english\", ngram_range=(1, 3), max_features=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e775a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_word_doc_matrix = tfidf_vectorizer.fit_transform(\n",
    "    training_data[\"tweet_text_cleaned\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code takes 30 seconds\n",
    "tfidf_embedding = umap.UMAP(metric=\"hellinger\").fit(tfidf_word_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=tfidf_embedding.embedding_[:, 0],\n",
    "    y=tfidf_embedding.embedding_[:, 1],\n",
    "    hue=training_data[\"tweet_sentiment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f52fc6c00c2d6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Traditional classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4186d",
   "metadata": {},
   "source": [
    "## Split data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee3ce5",
   "metadata": {},
   "source": [
    "Split training data into training and validation for performing K-fold cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd946bae2896c2e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_data[\"tweet_text_cleaned\"],\n",
    "    training_data[\"tweet_sentiment\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=training_data[\"tweet_sentiment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940961240c2196",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training data: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Test data: {y_test.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45162877121e8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d94a150f1d9626",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_bayes_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e9881f216f408",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect\": [TfidfVectorizer(), CountVectorizer()],\n",
    "    \"vect__stop_words\": [\"english\"],\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    \"vect__min_df\": [5, 10, 15],\n",
    "    \"vect__max_features\": (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__alpha\": (0.01, 0.1, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be833cc5dc1333f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_bayes_grid_search = GridSearchCV(\n",
    "    naive_bayes_pipeline, parameters, cv=5, n_jobs=-1, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215526263d92824",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code takes 6 minutes and 45 seconds\n",
    "naive_bayes_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1efe95614c2088",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % naive_bayes_grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = naive_bayes_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94565f2817b4c26e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = naive_bayes_grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e00c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 --> negative\n",
    "# 1 --> positive\n",
    "# 2 --> neutral\n",
    "plot_confusion_matrix(y_test, y_pred, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model_path = models_weights_dir_path / \"naive_bayes_model.joblib\"\n",
    "joblib.dump(naive_bayes_grid_search.best_estimator_, naive_bayes_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeefe35611fa28",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6f769bb231c0e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_regression_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(max_iter=500, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5ed6eefdd1a93",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect\": [TfidfVectorizer(), CountVectorizer()],\n",
    "    \"vect__stop_words\": [\"english\"],\n",
    "    \"vect__min_df\": [10, 15, 25],\n",
    "    \"vect__max_features\": (500, 1000),\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0e31f8784ecb3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_regression_grid_search = GridSearchCV(\n",
    "    logistic_regression_pipeline, parameters, cv=5, n_jobs=-1, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5f800efdf5c69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code takes 3 minutes\n",
    "logistic_regression_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72862ff86bc6af62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % logistic_regression_grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = logistic_regression_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a613752f7e4e55",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the best grid search pipeline on the test dataset\n",
    "y_pred = logistic_regression_grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f31bc9415fc03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0 --> negative\n",
    "# 1 --> positive\n",
    "# 2 --> neutral\n",
    "plot_confusion_matrix(y_test, y_pred, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a695b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(\n",
    "    logistic_regression_grid_search.best_estimator_,\n",
    "    models_weights_dir_path / \"logistic_regression_model.joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440714a7",
   "metadata": {},
   "source": [
    "## SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(max_features=1000, min_df=10, stop_words=\"english\")),\n",
    "        (\"clf\", SVC(random_state=42)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666aa630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code takes 2 minutes and 20 seconds\n",
    "svm_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715130a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 --> negative\n",
    "# 1 --> positive\n",
    "# 2 --> neutral\n",
    "plot_confusion_matrix(y_test, y_pred, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm_pipeline, models_weights_dir_path / \"svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e9f9a3fb213a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c342e",
   "metadata": {},
   "source": [
    "## Load GloVe embedding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64951242",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file_name = \"glove.6B.100d.txt\"\n",
    "glove_embedding_dict = load_embedding(data_dir_path / embedding_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of words in GloVe embedding: {len(glove_embedding_dict):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(tweets_list):\n",
    "    for tweet in tweets_list:\n",
    "        yield tweet.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5892d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max tokens to 5000\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "min_freq = 5\n",
    "max_tokens = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    iterator=yield_tokens(training_data[\"tweet_text_cleaned\"].tolist()),\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    "    max_tokens=max_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ab39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c7a1e",
   "metadata": {},
   "source": [
    "## Build embedding matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = torch.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282279f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11374c7d",
   "metadata": {},
   "source": [
    "Initialize the `embedding_matrix` with `GloVe` vectors.\n",
    "\n",
    "If a given word from the vocab don't have a corresponding `GloVe` embedding, initialized it with a _random_ embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tqdm(vocab.get_stoi().items()):\n",
    "    if word in glove_embedding_dict:\n",
    "        embedding_matrix[idx] = torch.tensor(glove_embedding_dict[word])\n",
    "    else:\n",
    "        unknown_words.append(word)\n",
    "        embedding_matrix[idx] = torch.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c09798",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(unknown_words)} ({len(unknown_words) / len(vocab):.2f}%) words in the vocabulary that are not in the GloVe embedding.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833deab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595badb",
   "metadata": {},
   "source": [
    "## Define Datasets and Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60561eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(training_data[\"tweet_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150792cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(\n",
    "    tweet_ids=training_data[\"tweet_id\"],\n",
    "    tweets=training_data[\"tweet_text_cleaned\"],\n",
    "    labels=training_data[\"tweet_sentiment\"],\n",
    "    vocab=vocab,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "development_dataset = TweetsDataset(\n",
    "    tweet_ids=development_data[\"tweet_id\"],\n",
    "    tweets=development_data[\"tweet_text_cleaned\"],\n",
    "    labels=development_data[\"tweet_sentiment\"],\n",
    "    vocab=vocab,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_dataset = TweetsDataset(\n",
    "    tweet_ids=test1_data[\"tweet_id\"],\n",
    "    tweets=test1_data[\"tweet_text_cleaned\"],\n",
    "    labels=test1_data[\"tweet_sentiment\"],\n",
    "    vocab=vocab,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a072b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_dataset = TweetsDataset(\n",
    "    tweet_ids=test2_data[\"tweet_id\"],\n",
    "    tweets=test2_data[\"tweet_text_cleaned\"],\n",
    "    labels=test2_data[\"tweet_sentiment\"],\n",
    "    vocab=vocab,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_dataset = TweetsDataset(\n",
    "    tweet_ids=test3_data[\"tweet_id\"],\n",
    "    tweets=test3_data[\"tweet_text_cleaned\"],\n",
    "    labels=test3_data[\"tweet_sentiment\"],\n",
    "    vocab=vocab,\n",
    "    label_encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea70e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    tweet_ids = np.array([item[0] for item in batch])\n",
    "    tweets = [item[1] for item in batch]\n",
    "    labels = np.array([item[2] for item in batch])\n",
    "\n",
    "    padded_tweets = pad_sequence(tweets, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "    return tweet_ids, padded_tweets, torch.from_numpy(labels).to(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd76b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "development_dataloader = DataLoader(\n",
    "    development_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test1_dataloader = DataLoader(\n",
    "    test1_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test2_dataloader = DataLoader(\n",
    "    test2_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test3_dataloader = DataLoader(\n",
    "    test3_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dd64e",
   "metadata": {},
   "source": [
    "## LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23588aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 3\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd76a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The LSTM model has {count_parameters(lstm_model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.embedding.weight.data = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "lr = 5e-4\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54598c29f00171b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_model_path = models_weights_dir_path / \"lstm_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5937507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code takes one minute\n",
    "metrics = training_loop(\n",
    "    n_epochs,\n",
    "    train_dataloader,\n",
    "    development_dataloader,\n",
    "    lstm_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    False,\n",
    "    None,\n",
    "    lstm_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e58b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, \"Bi-LSTM with 2 layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5c4011a8ab34d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load(lstm_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = get_labels_and_predictions(\n",
    "    lstm_model, development_dataloader, encoder, device, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 --> negative\n",
    "# 1 --> positive\n",
    "# 2 --> neutral\n",
    "plot_confusion_matrix(y_true, y_pred, \"Bi-LSTM with 2 layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d82eb",
   "metadata": {},
   "source": [
    "## LSTM with Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 300\n",
    "output_dim = 3\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model = LSTMWithAttention(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce720f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The LSTM with attention model has {count_parameters(lstm_with_attention_model):,} trainable parameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a154c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model.embedding.weight.data = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "lr = 5e-4\n",
    "optimizer = torch.optim.Adam(lstm_with_attention_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9320606",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model = lstm_with_attention_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7eac2310abd2d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_with_attention_model_path = (\n",
    "    models_weights_dir_path / \"lstm_with_attention_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b83cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = training_loop(\n",
    "    n_epochs,\n",
    "    train_dataloader,\n",
    "    development_dataloader,\n",
    "    lstm_with_attention_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    False,\n",
    "    None,\n",
    "    lstm_with_attention_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, \"Bi-LSTM with attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453730ac214767fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_with_attention_model.load_state_dict(torch.load(lstm_with_attention_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = get_labels_and_predictions(\n",
    "    lstm_with_attention_model, development_dataloader, encoder, device, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ffac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 --> negative\n",
    "# 1 --> positive\n",
    "# 2 --> neutral\n",
    "plot_confusion_matrix(y_true, y_pred, \"Bi-LSTM with attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2aa26c",
   "metadata": {},
   "source": [
    "## BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = \"bert-base-uncased\"\n",
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(transformer_name)\n",
    "bert_transformer = transformers.AutoModel.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_transformer.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "n_epochs = 3\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca10271",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_name, feature_column in [\n",
    "    (\"bert_raw_tweets\", \"tweet_text\"),\n",
    "    (\"bert_cleaned_tweets\", \"tweet_text_cleaned\"),\n",
    "]:\n",
    "    # create BERT-based dataset\n",
    "    bert_train_dataset = BERTTweetsDataset(\n",
    "        tweet_ids=training_data[\"tweet_id\"],\n",
    "        tweets=training_data[feature_column],\n",
    "        labels=training_data[\"tweet_sentiment\"],\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_encoder=encoder,\n",
    "    )\n",
    "\n",
    "    bert_development_dataset = BERTTweetsDataset(\n",
    "        tweet_ids=development_data[\"tweet_id\"],\n",
    "        tweets=development_data[feature_column],\n",
    "        labels=development_data[\"tweet_sentiment\"],\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_encoder=encoder,\n",
    "    )\n",
    "\n",
    "    # create dataloaders\n",
    "    bert_train_dataloader = DataLoader(\n",
    "        bert_train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    bert_development_dataloader = DataLoader(\n",
    "        bert_development_dataset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    bert_model = BERTClassifier(\n",
    "        transformer=bert_transformer, output_dim=len(encoder.classes_), freeze=False\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(bert_model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    bert_model = bert_model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    print(\n",
    "        f\"The BERT sentiment model has {count_parameters(bert_model):,} trainable parameters\"\n",
    "    )\n",
    "\n",
    "    bert_model_path = models_weights_dir_path / f\"{experiment_name}.pt\"\n",
    "\n",
    "    metrics = training_loop(\n",
    "        n_epochs,\n",
    "        bert_train_dataloader,\n",
    "        bert_development_dataloader,\n",
    "        bert_model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        True,\n",
    "        None,\n",
    "        bert_model_path,\n",
    "    )\n",
    "\n",
    "    plot_metrics(metrics, experiment_name)\n",
    "\n",
    "    bert_model.load_state_dict(torch.load(bert_model_path))\n",
    "\n",
    "    y_true, y_pred = get_labels_and_predictions(\n",
    "        bert_model,\n",
    "        bert_development_dataloader,\n",
    "        encoder,\n",
    "        device,\n",
    "        True,\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe8258b",
   "metadata": {},
   "source": [
    "# Calculating predictions on test1, test2, and test3 datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03459549",
   "metadata": {},
   "source": [
    "In this section, we will load saved models in the `models_weights` folder, and calculate predictions and `f1` score for the three testing datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1a70b",
   "metadata": {},
   "source": [
    "## Naive Bayes, Logistic Regression, and SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_pipeline = joblib.load(models_weights_dir_path / \"naive_bayes_model.joblib\")\n",
    "logistic_regression_pipeline = joblib.load(\n",
    "    models_weights_dir_path / \"logistic_regression_model.joblib\"\n",
    ")\n",
    "svm_pipeline = joblib.load(models_weights_dir_path / \"svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data, test_data_name in [\n",
    "    (test1_data, \"test1\"),\n",
    "    (test2_data, \"test2\"),\n",
    "    (test3_data, \"test3\"),\n",
    "]:\n",
    "    y_true = test_data[\"tweet_sentiment\"]\n",
    "\n",
    "    y_pred_nb = naive_bayes_pipeline.predict(test_data[\"tweet_text_cleaned\"])\n",
    "    y_pred_lr = logistic_regression_pipeline.predict(test_data[\"tweet_text_cleaned\"])\n",
    "    y_pred_svm = svm_pipeline.predict(test_data[\"tweet_text_cleaned\"])\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred_nb, f\"Naive Bayes - {test_data_name}\")\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred_lr,\n",
    "        f\"Logistic Regression - {test_data_name}\",\n",
    "    )\n",
    "\n",
    "    # 0 --> negative\n",
    "    # 1 --> positive\n",
    "    # 2 --> neutral\n",
    "    plot_confusion_matrix(y_true, y_pred_svm, f\"SVM - {test_data_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f25544",
   "metadata": {},
   "source": [
    "## LSTM, LSTM with attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7880c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load(models_weights_dir_path / \"lstm_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_with_attention_model.load_state_dict(\n",
    "    torch.load(models_weights_dir_path / \"lstm_with_attention_model.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data, test_data_name in [\n",
    "    (test1_data, \"test1\"),\n",
    "    (test2_data, \"test2\"),\n",
    "    (test3_data, \"test3\"),\n",
    "]:\n",
    "    test_dataset = TweetsDataset(\n",
    "        tweet_ids=test_data[\"tweet_id\"],\n",
    "        tweets=test_data[\"tweet_text_cleaned\"],\n",
    "        labels=test_data[\"tweet_sentiment\"],\n",
    "        vocab=vocab,\n",
    "        label_encoder=encoder,\n",
    "    )\n",
    "\n",
    "    batch_size = 256\n",
    "\n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    "    )\n",
    "\n",
    "    y_true, y_pred = get_labels_and_predictions(\n",
    "        lstm_model, test_data_loader, encoder, device, False\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred, f\"Bi-LSTM - {test_data_name}\")\n",
    "\n",
    "    y_true, y_pred = get_labels_and_predictions(\n",
    "        lstm_with_attention_model, test_data_loader, encoder, device, False\n",
    "    )\n",
    "\n",
    "    # 0 --> negative\n",
    "    # 1 --> positive\n",
    "    # 2 --> neutral\n",
    "    plot_confusion_matrix(y_true, y_pred, f\"Bi-LSTM with attention - {test_data_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e269ea",
   "metadata": {},
   "source": [
    "## BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ee915",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_transformer = transformers.AutoModel.from_pretrained(transformer_name)\n",
    "\n",
    "bert_raw_tweets = BERTClassifier(\n",
    "    transformer=bert_transformer, output_dim=len(encoder.classes_), freeze=False\n",
    ")\n",
    "\n",
    "bert_raw_tweets.load_state_dict(\n",
    "    torch.load(models_weights_dir_path / \"bert_raw_tweets.pt\")\n",
    ")\n",
    "\n",
    "bert_raw_tweets = bert_raw_tweets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_transformer = transformers.AutoModel.from_pretrained(transformer_name)\n",
    "\n",
    "bert_cleaned_tweets = BERTClassifier(\n",
    "    transformer=bert_transformer, output_dim=len(encoder.classes_), freeze=False\n",
    ")\n",
    "\n",
    "bert_cleaned_tweets.load_state_dict(\n",
    "    torch.load(models_weights_dir_path / \"bert_cleaned_tweets.pt\")\n",
    ")\n",
    "\n",
    "bert_cleaned_tweets = bert_cleaned_tweets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data, test_data_name in [\n",
    "    (test1_data, \"test1\"),\n",
    "    (test2_data, \"test2\"),\n",
    "    (test3_data, \"test3\"),\n",
    "]:\n",
    "\n",
    "    bert_dataset = BERTTweetsDataset(\n",
    "        tweet_ids=test_data[\"tweet_id\"],\n",
    "        tweets=test_data[\"tweet_text\"],\n",
    "        labels=test_data[\"tweet_sentiment\"],\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_encoder=encoder,\n",
    "    )\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    bert_data_loader = DataLoader(bert_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    y_true, y_pred = get_labels_and_predictions(\n",
    "        bert_raw_tweets, bert_data_loader, encoder, device, True\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred, f\"BERT raw tweets - {test_data_name}\")\n",
    "\n",
    "    bert_dataset = BERTTweetsDataset(\n",
    "        tweet_ids=test_data[\"tweet_id\"],\n",
    "        tweets=test_data[\"tweet_text_cleaned\"],\n",
    "        labels=test_data[\"tweet_sentiment\"],\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_encoder=encoder,\n",
    "    )\n",
    "\n",
    "    bert_data_loader = DataLoader(bert_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    y_true, y_pred = get_labels_and_predictions(\n",
    "        bert_cleaned_tweets, bert_data_loader, encoder, device, True\n",
    "    )\n",
    "\n",
    "    # 0 --> negative\n",
    "    # 1 --> positive\n",
    "    # 2 --> neutral\n",
    "    plot_confusion_matrix(y_true, y_pred, f\"BERT cleaned tweets - {test_data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095345a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
